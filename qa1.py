# -*- coding: utf-8 -*-
"""QA1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sRJW1Cc88Qg-Ns3Zh08ZkCPyZ8NSskap
"""

from pythainlp.tokenize import word_tokenize
import re
import json

def search_answer_pattern (question , article):
  '''
  (str,str)=> (list,str)
  create pattern for finding answer 
  param:
    question: ประโยคคำถาม
    article : หัวเรื่องที่เลือกขึ้นมาจากคำถาม
  return string of pattern
  '''
  #from pythainlp.tokenize import word_tokenize
  #import re
  q_word = ['อะไร','ใคร','ที่ไหน','ไหน','ใด','กี่','อย่างไร','ชนิดใด','เมื่อไหร่']
  
  
  
  q_list = word_tokenize(question.replace(article,'article'))
  #pattern = ''
  map_ans_str = '([ก-ํ]+)'
  map_ans_date = '([ก-ํ]+.[ก-ํ].[ก-ํ].[0-9]{4})'
  map_ans_number = '([0-9]+)'
  map_ans = ''
  map_pattern = []
  for q in q_list:
    if q in q_word:
       if q == 'กี่':
           map_ans = map_ans_number
           
       elif q == 'เมื่อใด' or q == 'เมื่อไหร่':
           map_ans = map_ans_date
       
       else:
           map_ans = map_ans_str
       map_pattern.append(map_ans)
    if q == 'article':
       map_pattern.append(article)
    elif q not in q_word :
       map_pattern.append(q)
                       
  
  
  return make_pattern(map_pattern,map_ans)


def make_pattern( map_pattern_list,map_ans):
  '''
  (list,str) => list of str
  param:
  map_pattern_list : list of word to make pattern. ex, ['article','เป็น','เมืองหลวง','ของ','ประเทศ','(ก-ํ)'] 
  map_ans : list of  answer's pattern format . ex. (ก-ํ)
  จัดรูปแบบที่เป็นไปได้เกือบทั้งหมดของแพทเทิร์นนั้น
  return list of pattern strings 
  
  '''
 
  p_list=[]
  if map_pattern_list[0] == map_ans:
    map_pattern_list[0] = '\s'+str(map_ans)
  #elif  map_pattern_list[-1] == map_ans:
  map_pattern_list[-1] = str(map_ans)+str('\s')
 
  p_list.append(''.join(map_pattern_list)) 
  i = 1
  while i < len(map_pattern_list)-1:
    #เติมทีละ i ตัว จนถึง จน ช่องว่าง-1 ตัว
    p_pattern = '.*'.join(map_pattern_list[0:i+1])+''.join(map_pattern_list[i+1:]) 
    
    p_list.append( p_pattern) 
    i = i+1
  
 
  return p_list

def get_answer(question,article,article_dic):
  '''
  (str,str,dic) => str
  finding answer in article document
  #pattern search
  
  parameters:
   question : input question
   article  : name of selected article
   article_dic : dictionary where key = article , values = article file names
  return 
   answer that can find in this article
   
  '''
  file= open('wiki_data/'+article_dic[article]+'.txt', 'r',encoding ='utf-8')
  data = file.read()
 
  search_pattern = search_answer_pattern (question ,article)
  #print (search_pattern)
  for pattern in search_pattern:
    ans = re.findall(pattern,data)
    if len(ans) != 0:
      return [ans[0],article_dic[article]]
  return ''

def answer(question,freq_word_dic,article_list,article_dic):
  '''
  (str,dic,list,dic) => str
  finding answer in all selected documents until get answer or out of list
  parameters:
    question : input question
    freq_word_dic : dictionary where key = article , values = frequency of article in all files
    article_list : list of all articles
    article_dic : dictionary where key = article ,value = file of article 
  return : answer
  '''
  
  sorted_key_article_list = get_final_article_list(question,freq_word_dic,article_list,article_dic)
  print ('เอกสารที่เกี่ยวข้อง : ',sorted_key_article_list) #=====================================================check will delete
  final_answer ='ไม่พบคำตอบ'
  for article in sorted_key_article_list:
    final_answer = get_answer(question,article,article_dic) 
    if final_answer != '':
      return final_answer
  return final_answer

def get_final_article_list(question,freq_word_dic,article_list,article_dic):
    '''
    คัดเลือกหัวหัวข้อเอกสารและเรียงลำดับโดยอิงจากจำนวนคำสำคัญ
    param:
        question : input question
        freq_word_dic = dictionary where keys = words , values = amount of word in all documents
        article_list  = list of all articles 
        article_dic  = dictionary where keys = article , values = article_id 
    return:
        list of related article
    '''
    pk =prioritize_keyword (  get_key_article_list (question ,article_list) , freq_word_dic)
    #print('final_article_list' , pk)
    tmp = []
    for i in pk:
        file = open('wiki_data/'+article_dic[i]+'.txt','r' , encoding = 'utf-8')
        data = file.read()
        file.close()
        tmp.append((get_article_score(data,i),i))
    return sorted([article[1] for article in tmp])
        
def get_key_article_list (question ,article_list):
  '''
  (str,list) => list
  get key article list for searching answer
  paramerters:
   question : input question
   article_list : list of all articles
  return
   list of key article
   
  '''

  return [word for word in tokenize_text(question,article_list) if word in article_list]

def prioritize_keyword ( key_article_list , freq_word_dic):
  '''
  (list,dic)=>list
  จัดลำดับความสำคัญของชื่อหัวข้อ
  parameters :
  key_article_list : ชื่อหัวข้อที่มีอยู่ในคำถาม
  freq_word_doc : เก็บ key เป็น ชื่อหัวข้อ (article) ค่าเป็นจำนวนความถี่ โดยเรียงความถี่มาอยู่แล้วจากมากไปน้อย
  return prioritize article list
  
  '''
  #for i in key_article_list:
   #print (i,freq_word_dic[i])
  
  #ans =   sorted ( [ (freq_word_dic[article],article) for article in key_article_list if freq_word_dic[article] ] )
  ans = []
  for article in key_article_list:
      try:
         ans.append( (freq_word_dic[article],article))
      except KeyError:
         print ('key error',article )
    
  
  article_sorted_list = [item[1]for item in sorted(ans)]
  
  return article_sorted_list

def get_article_score ( data, key_article_list  ):
  '''
  (str,str) => int 
  ถ้ามีคำใน key_article เยอะก็น่าจะมีความน่าจะเป็นที่จะมีคำตอบอยู่ในไฟล์นี้
  param :
    question : คำถามทั้งหมดที่ถาม
    #article_file_name : ชื่อไฟล์ของหัวข้อนั้นๆ
    data = ข้อมูลในเอกสาร
   
  '''
  score = 0 
  
  for q in key_article_list :
    if q in data:
      score+=1
  return score

def tokenize_text(text,article_list):
  '''
  (str,) => list of str
  help tokenize by using article list
  paramerters:
   text : text
   article_list : list of article 
  return
   list of key article
   
  '''
 
  raw_tokens = word_tokenize(text) #  , engine = 'deepcut')
  #print ('raw_tokens',raw_tokens)
  key_article_list = []
  tokens =[]
  i = 0
  pivot_s = 0
  pivot_e = 0
  #prop_article = ''
  while i < len(raw_tokens):
    
    j = i
    pivot_s = i
    pivot_e = 0
    while j < len(raw_tokens):
        tmp1 = ''.join(raw_tokens[i:j+1])
        tmp2 = ' '.join(raw_tokens[i:j+1])
        if tmp1 in article_list:
          #print (tmp)
          pivot_s  = i
          pivot_e = j
        elif tmp2 in article_list:
          pivot_s  = i
          pivot_e = j
        
        j = j+1
    if raw_tokens[i] != ' ':
      if pivot_e != 0:
        i = pivot_e
        prop_article = ''.join(raw_tokens[pivot_s:pivot_e+1])
      
        tokens.append(prop_article)
      elif pivot_e == 0 and raw_tokens[i] in article_list:
        key_article_list.append(raw_tokens[i])
        tokens.append(raw_tokens[i])
      else :
        tokens.append(raw_tokens[i])
      
      i = i+1
 
  return tokens

#if__name__ = "__main__" :
def  main():
    file_dic = open ('id_dic_1.txt','r')
    id_dic = json.loads(file_dic.read())
    file_dic.close()
    file_article = open('arti_list_1.txt','r')
    article_list = json.loads(file_article.read())
    #print(article_list)
    file_article.close()
    #print ('running in main ')
    #print (article_list)
    freq_file = open('freq_article_in_flie_json_2.txt','r')
    freq_article = json.loads(freq_file.read())
    freq_file.close()
    #print (get_answer('เฮโจเกียว','เฮโจเกียว',id_dic))
    
    will_do = True
    while (will_do):
        question = input("คำถามของคุณคือ ")
        print ('คำตอบ, หมายเลขของเอกสาร  :',answer(question,freq_article,article_list,id_dic))
        next_question = input("จะถามต่อหรือไม่ [y,n]")
        will_do = next_question=='y'
   